{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources: \n",
    "# https://github.com/spmallick/learnopencv/tree/master/Face-Recognition-with-ArcFace\n",
    "# https://github.com/ZhaoJ9014/face.evoLVe.PyTorch/blob/master/util/extract_feature_v1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    model_path = \"arc-mbv2-int8.tflite\"\n",
    "    data_dir = \"data/\"\n",
    "    input_size = 112\n",
    "    \n",
    "flags = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = cv2.imread(flags.person1 + \"_0001.jpg\")\n",
    "img = cv2.resize(orig_img, (flags.input_size, flags.input_size))\n",
    "input_data = np.reshape(np.array(img, np.float32), (1, flags.input_size, flags.input_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(input_size=[112, 112], embedding_size=512):\n",
    "    images = []\n",
    "    resized_images = []\n",
    "    directory = flags.data_dir\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        orig_img = cv2.imread(f)\n",
    "        img = cv2.resize(orig_img, (input_size[0], input_size[1]))\n",
    "        images.append(img)\n",
    "        img = np.reshape(np.array(img, np.float32), (1, input_size[0], input_size[1], 3))\n",
    "        resized_images.append(img)\n",
    "    \n",
    "    interpreter = tf.lite.Interpreter(model_path=flags.model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    embeddings = np.zeros([len(resized_images), embedding_size])\n",
    "    for idx, img in enumerate(resized_images):\n",
    "        interpreter.set_tensor(input_details[0]['index'], img)\n",
    "        interpreter.invoke()\n",
    "        embeddings[idx, :] = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return images, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_grid(cos_similarity, input_size):\n",
    "    n = len(cos_similarity)\n",
    "    rows = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        for j in range(n):\n",
    "            # create small colorful image from value in distance matrix\n",
    "            value = cos_similarity[i][j]\n",
    "            cell = np.empty(input_size)\n",
    "            cell.fill(value)\n",
    "            cell = (cell * 255).astype(np.uint8)\n",
    "            # color depends on value: blue is closer to 0, green is closer to 1\n",
    "            img = cv2.applyColorMap(cell, cv2.COLORMAP_WINTER)\n",
    "\n",
    "            # add distance value as text centered on image\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            text = f\"{value:.2f}\"\n",
    "            textsize = cv2.getTextSize(text, font, 1, 2)[0]\n",
    "            text_x = (img.shape[1] - textsize[0]) // 2\n",
    "            text_y = (img.shape[0] + textsize[1]) // 2\n",
    "            cv2.putText(\n",
    "                img, text, (text_x, text_y), font, 1, (255, 255, 255), 2, cv2.LINE_AA,\n",
    "            )\n",
    "            row.append(img)\n",
    "        rows.append(np.concatenate(row, axis=1))\n",
    "    grid = np.concatenate(rows)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_similarity(tag, input_size=[112, 112]):\n",
    "    images, embeddings = get_embeddings()\n",
    " \n",
    "    # calculate cosine similarity matrix\n",
    "    cos_similarity = np.dot(embeddings, embeddings.T)\n",
    "    cos_similarity = cos_similarity.clip(min=0, max=1)\n",
    "    # plot grid from pair distance values in similarity matrix\n",
    "    similarity_grid = plot_similarity_grid(cos_similarity, input_size)\n",
    " \n",
    "    # pad similarity grid with images of faces\n",
    "    horizontal_grid = np.hstack(images)\n",
    "    vertical_grid = np.vstack(images)\n",
    "    zeros = np.zeros((*input_size, 3))\n",
    "    vertical_grid = np.vstack((zeros, vertical_grid))\n",
    "    result = np.vstack((horizontal_grid, similarity_grid))\n",
    "    result = np.hstack((vertical_grid, result))\n",
    " \n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    " \n",
    "    cv2.imwrite(f\"results/{tag}.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_297161/2741622474.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_297161/2012059094.py\u001b[0m in \u001b[0;36mvisualize_similarity\u001b[0;34m(tag, input_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"results/{tag}.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'results'"
     ]
    }
   ],
   "source": [
    "visualize_similarity(\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4935064935064934"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6000/924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
