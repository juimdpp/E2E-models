{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app, flags, logging\n",
    "from absl.flags import FLAGS\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import sys\n",
    "import yaml\n",
    "# from modules.models import RetinaFaceModel\n",
    "# from modules.utils import (set_memory_growth, load_yaml, draw_bbox_landm,\n",
    "#                            pad_input_image, recover_pad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flags:\n",
    "    cfg_path = 'retinaface_res50.yaml' # config file path\n",
    "    model_path = 'retinaface-mbv2-int8.tflite'\n",
    "    gpu = '0' # 'which gpu to use'\n",
    "    img_path = '0_Parade_marchingband_1_149.jpg' # 'path to input image'\n",
    "    webcam = False  # 'get image source from webcam or not'\n",
    "    iou_th = 0.4  # 'iou threshold for nms'\n",
    "    score_th = 0.5  # 'score threshold for nms'\n",
    "    down_scale_factor = 1.0  # 'down-scale factor for inputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_landm(img, ann, img_height, img_width):\n",
    "    \"\"\"draw bboxes and landmarks\"\"\"\n",
    "    # bbox\n",
    "    x1, y1, x2, y2 = int(ann[0] * img_width), int(ann[1] * img_height), \\\n",
    "                     int(ann[2] * img_width), int(ann[3] * img_height)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # confidence\n",
    "    text = \"{:.4f}\".format(ann[15])\n",
    "    cv2.putText(img, text, (int(ann[0] * img_width), int(ann[1] * img_height)),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255))\n",
    "\n",
    "    # landmark\n",
    "    if ann[14] > 0:\n",
    "        cv2.circle(img, (int(ann[4] * img_width),\n",
    "                         int(ann[5] * img_height)), 1, (255, 255, 0), 2)\n",
    "        cv2.circle(img, (int(ann[6] * img_width),\n",
    "                         int(ann[7] * img_height)), 1, (0, 255, 255), 2)\n",
    "        cv2.circle(img, (int(ann[8] * img_width),\n",
    "                         int(ann[9] * img_height)), 1, (255, 0, 0), 2)\n",
    "        cv2.circle(img, (int(ann[10] * img_width),\n",
    "                         int(ann[11] * img_height)), 1, (0, 100, 255), 2)\n",
    "        cv2.circle(img, (int(ann[12] * img_width),\n",
    "                         int(ann[13] * img_height)), 1, (255, 0, 100), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Processing on single image 0_Parade_marchingband_1_149.jpg\n",
      "raw shape (684, 1024, 3)\n",
      "(684, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags()\n",
    "# init\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.disabled = True\n",
    "logger.setLevel(logging.FATAL)\n",
    "#     set_memory_growth()\n",
    "\n",
    "with open(FLAGS.cfg_path, 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# define network\n",
    "interpreter = tf.lite.Interpreter(FLAGS.model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "print(\"[*] Processing on single image {}\".format(FLAGS.img_path))\n",
    "\n",
    "img_raw = cv2.imread(FLAGS.img_path)\n",
    "print('raw shape', img_raw.shape)\n",
    "img_height_raw, img_width_raw, _ = img_raw.shape\n",
    "img = np.float32(img_raw.copy())\n",
    "\n",
    "if FLAGS.down_scale_factor < 1.0:\n",
    "    img = cv2.resize(img, (0, 0), fx=FLAGS.down_scale_factor,\n",
    "                     fy=FLAGS.down_scale_factor,\n",
    "                     interpolation=cv2.INTER_LINEAR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# pad input image to avoid unmatched shape problem\n",
    "def pad_input_image(img, max_steps):\n",
    "    \"\"\"pad image to suitable shape\"\"\"\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    img_pad_h = 0\n",
    "    if img_h % max_steps > 0:\n",
    "        img_pad_h = max_steps - img_h % max_steps\n",
    "\n",
    "    img_pad_w = 0\n",
    "    if img_w % max_steps > 0:\n",
    "        img_pad_w = max_steps - img_w % max_steps\n",
    "\n",
    "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
    "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
    "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
    "    pad_params = (1, img_h, img_w, img_pad_h, img_pad_w)\n",
    "\n",
    "    return img, pad_params\n",
    "#         img, pad_params = pad_input_image(img, max_steps=max(cfg['steps']))\n",
    "\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (640, 640))\n",
    "img = np.reshape(np.array(img), (1, cfg['input_size'], cfg['input_size'], 3))\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], img)\n",
    "\n",
    "# run model\n",
    "interpreter.invoke()\n",
    "\n",
    "outputs = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags()\n",
    "# init\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "\n",
    "logger = tf.get_logger()\n",
    "logger.disabled = True\n",
    "logger.setLevel(logging.FATAL)\n",
    "#     set_memory_growth()\n",
    "\n",
    "with open(FLAGS.cfg_path, 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# define network\n",
    "interpreter = tf.lite.Interpreter()\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "print(\"[*] Processing on single image {}\".format(FLAGS.img_path))\n",
    "\n",
    "img_raw = cv2.imread(FLAGS.img_path)\n",
    "print('raw shape', img_raw.shape)\n",
    "img_height_raw, img_width_raw, _ = img_raw.shape\n",
    "img = np.float32(img_raw.copy())\n",
    "\n",
    "if FLAGS.down_scale_factor < 1.0:\n",
    "    img = cv2.resize(img, (0, 0), fx=FLAGS.down_scale_factor,\n",
    "                     fy=FLAGS.down_scale_factor,\n",
    "                     interpolation=cv2.INTER_LINEAR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# pad input image to avoid unmatched shape problem\n",
    "def pad_input_image(img, max_steps):\n",
    "    \"\"\"pad image to suitable shape\"\"\"\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    img_pad_h = 0\n",
    "    if img_h % max_steps > 0:\n",
    "        img_pad_h = max_steps - img_h % max_steps\n",
    "\n",
    "    img_pad_w = 0\n",
    "    if img_w % max_steps > 0:\n",
    "        img_pad_w = max_steps - img_w % max_steps\n",
    "\n",
    "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
    "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
    "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
    "    pad_params = (1, img_h, img_w, img_pad_h, img_pad_w)\n",
    "\n",
    "    return img, pad_params\n",
    "#         img, pad_params = pad_input_image(img, max_steps=max(cfg['steps']))\n",
    "\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (640, 640))\n",
    "img = np.reshape(np.array(img), (1, cfg['input_size'], cfg['input_size'], 3))\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], img)\n",
    "\n",
    "# run model\n",
    "interpreter.invoke()\n",
    "\n",
    "outputs = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4384 0.99505967\n",
      "4404 0.99505967\n",
      "4514 0.99505967\n",
      "4524 0.99505967\n",
      "4544 0.99505967\n",
      "4564 0.99505967\n",
      "4674 0.99505967\n",
      "4696 0.99505967\n",
      "4734 0.99505967\n",
      "4744 0.99505967\n",
      "4894 0.99505967\n",
      "5982 0.99505967\n",
      "5994 0.99505967\n",
      "6116 0.99505967\n",
      "6129 0.99505967\n",
      "6130 0.99505967\n",
      "6142 0.99505967\n",
      "6186 0.99505967\n",
      "6203 0.99505967\n",
      "6204 0.99505967\n",
      "6346 0.99505967\n",
      "7271 0.99505967\n",
      "7273 0.99505967\n",
      "7419 0.99505967\n",
      "7421 0.99505967\n",
      "7431 0.99505967\n",
      "7433 0.99505967\n",
      "7459 0.99505967\n",
      "7461 0.99505967\n",
      "7567 0.99505967\n",
      "7603 0.99505967\n",
      "7633 0.99505967\n",
      "7635 0.99505967\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outputs)):\n",
    "    if outputs[i, -1]>0.99:\n",
    "        print(i, outputs[i,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 122\n",
      "[*] save result at out_0_Parade_marchingband_1_149.jpg\n"
     ]
    }
   ],
   "source": [
    "# recover padding effect\n",
    "#         outputs = recover_pad_output(outputs, pad_params)\n",
    "\n",
    "def nms(b1, b2):\n",
    "    xA = max(b1[0], b2[0])\n",
    "    yA = max(b1[1], b2[1])\n",
    "    xB = min(b1[2], b2[2])\n",
    "    yB = min(b1[3], b2[3])\n",
    "    \n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    \n",
    "    boxAArea = (b1[2] - b1[0] + 1) * (b1[3] - b1[0] + 1) \n",
    "    boxBArea = (b2[2] - b2[0] + 1) * (b2[3] - b2[0] + 1) \n",
    "    \n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "\n",
    "# draw and save results\n",
    "img_raw = cv2.imread(FLAGS.img_path)\n",
    "filtered = []\n",
    "save_img_path = os.path.join('out_' + os.path.basename(FLAGS.img_path))\n",
    "for prior_index in range(len(outputs)):\n",
    "    if outputs[prior_index, -1] > 0.6:\n",
    "        filtered.append(outputs[prior_index])\n",
    "\n",
    "nmsed = [filtered[0]]\n",
    "for f1 in filtered:\n",
    "    for f2 in nmsed:\n",
    "#         print(nms(f1, f2))\n",
    "        if nms(f1, f2)<0.5:\n",
    "            nmsed.append(f1)\n",
    "            break\n",
    "print(len(nmsed), len(filtered))\n",
    "for f in nmsed:\n",
    "    draw_bbox_landm(img_raw, f, img_height_raw,\n",
    "                img_width_raw)\n",
    "cv2.imwrite(save_img_path, img_raw)\n",
    "print(f\"[*] save result at {save_img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "research_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
